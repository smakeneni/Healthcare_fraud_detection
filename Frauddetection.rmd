---
title: "Health care fraud detection"
author: "Spandana Makeneni"
output: 
  html_document:
    toc: true 
    toc_depth: 3
    df_print: kable
    toc_float: 
        collapsed: TRUE
        smooth_scroll: FALSE
    number_sections: FALSE
    messages: FALSE
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,warning=FALSE,message=FALSE)
```

<style>
body {
text-align: justify}
</style>

<style>
div.blue { background-color:#e6f0ff; border: 1px solid black; padding: 5px;}
</style>

<style>
div.black { background-color:#8FBC8F; border: 1px solid black; padding: 5px;}
</style>

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(ggthemr)
library(ggpubr)
library(naniar)
library(ggridges)
library(moments)
library(caret)
library(rcompanion)
library(gbm)
library(xgboost)
library(Metrics)
library(randomForest)
library(ROCR)
ggthemr(palette = "flat")

train_beneficiary <- read.csv("/Users/spandana/Desktop/Data_science_projects/Healthcare_fraud_detection/Train_Beneficiarydata.csv")
train_inpatient <- read.csv("/Users/spandana/Desktop/Data_science_projects/Healthcare_fraud_detection/Train_Inpatientdata.csv")
train_outpatient <- read.csv("/Users/spandana/Desktop/Data_science_projects/Healthcare_fraud_detection/Train_Outpatientdata.csv")
train_labels <- read.csv("/Users/spandana/Desktop/Data_science_projects/Healthcare_fraud_detection/Train.csv")
States <- read.csv("/Users/spandana/Desktop/Data_science_projects/Healthcare_fraud_detection/States.csv",header=FALSE)
colnames(States)<-c("State","State_name")
```

#Goal
<div class = "blue">
The goal of this project is to use machine learning to predict fraudulent health providers by analyzing patterns across inpatient and outpatient claims data.
</div>

#Background
##Impact of health care fraud
* U.S spends ~3.6 trillion on health insurance claims every year  
* ~$300 billion(3-10% of claims) are fraudulent health care claims  
* Examples of fraudulent claims:  
  + Billing for service that were not provided  
  + Misrepresenting the services provided (charging for a more complex procedure)
  + Submitting duplicate claims for same or different patients
* Fraudulent claims cause:
  + Incresed cost of care
  + slow processing of valid claims
  + Higher premiums
* Manual review of billions of claims is **time consuming and expensive**

##Opportunity for machine learning 
* Machine learning is ideally suited to detect fraud claims 
* Models can be built on existing fraud patterns to automate assessment of claims
* Benefits:
  + Faster processing of all claims
    + Identify genuine claims and streamline the approval and payment process
    + Flag fraudulent claims for further review before payment
  + Can provide clear reasons for flagging
  + Models can be improved to find new patterns and therefore identiy new fraud types 


#Data set

There are 4 sets of data available. You can download them from kaggle   
**Inpatient Dataset** - Inpatient claims
**Outpatient Dataset** - Outpatient claims

In patient and outpatient claims data sets consist of:  

* Provider ID
* Beneficiary ID
* Claim ID
* Claim Start date
* Claim End date
* Physician information (3 columns)
* Diagnosis codes (10 columns)
* Procedure codes (6 columns)

Additionally **Inpatient datset** consists of Admission and Discharge dates 

**Beneficiary Dataset** - This data contains beneficiary KYC details like health conditions,region they belong to etc

- Beneficiary ID 
- Date of Birth
- Gender
- Race
- State
- Chronic condition information ( 1 column per condition - 11 columns)

**Provider labels** - Provider ID and labels (fraudulent and non-fraudulent)

![The inpatient and outpatient claims data provided are per patient while the labels are provided per provider](/Users/spandana/Desktop/datatestimage.png) 


##Challenge
**The challenge here is to analyze individual claims data and find patterns that might then help us predict fradulent providers. So, we are making an assumption that all claims filed by a fraudulent provider and fraud and vice versa.** 

#Data cleaning
Initial data cleaning:  

1) Dates were read as factors. Lets change that.
2) There are some missing values. Lets take a look at them.

```{r formattingdates}
date_colnames <- c("ClaimStartDt","ClaimEndDt","AdmissionDt","DischargeDt","DOB","DOD")
train_inpatient[,date_colnames[1:4]] <- lapply(train_inpatient[,date_colnames[1:4]],as.Date)
train_outpatient[,date_colnames[1:2]] <- lapply(train_outpatient[,date_colnames[1:2]],as.Date)
train_beneficiary[,date_colnames[5:6]] <- lapply(train_beneficiary[,date_colnames[5:6]],as.Date)
```

##Missing values
```{r checkingmissingvalues}
#Function to plot missing values 
plot_missingvalues <- function(df,title_name){
  df_missing <- miss_var_summary(df)
  df_missing <- df_missing %>% filter(pct_miss>0)
  p <- ggplot(df_missing,aes(x=reorder(variable,-pct_miss),y=pct_miss,label=round(pct_miss,1)))+geom_segment(aes(x=reorder(variable,-pct_miss),xend=reorder(variable,-pct_miss),y=0,yend=pct_miss))+geom_point(size=3.7,alpha=0.6)+geom_text(nudge_x=-0.09,nudge_y=4.0)+labs(y="% missing",x="",title=title_name)+ theme(plot.title = element_text(hjust = 0.5))+theme(axis.text = element_text(face="bold",size=12))+coord_flip()
  print(p)
}

plot1 <-plot_missingvalues(train_inpatient,"Missing values in Inpatient data")
plot2 <-plot_missingvalues(train_outpatient,"Missing values in Outpatient data")
plot3 <-plot_missingvalues(train_beneficiary,"Missing values in Beneficiary data")
#ggsave("Inpatient_missing.png",plot1,dpi=600)
#ggsave("Outpatient_missing.png",plot2,dpi=600)
#ggsave("Beneficiary.png",plot3,dpi=600)
```

**Lots of missing values in both inpatient and outpatient datsets**

##Dealing with missing values

**Step 1:**    
<div class = "black">
Dropping the following columns because 100% of the data is missing:  

1) ClmProcedure code 4,5,6 from the inpatient data 
2) ClmProcedureCode 1,2,3,4,5,6 from the outpatient data -  After researching a little I found that frequently these columns exist in the claims data but when they are not the basis of payment they are empty. 
3) DOD - Date of Death  
</div>

```{r dropping columns}
train_inpatient <- train_inpatient %>% select(-ClmProcedureCode_4,-ClmProcedureCode_5,-ClmProcedureCode_6)
train_outpatient <- train_outpatient %>%  select(-starts_with("ClmProcedure"))
train_beneficiary <- train_beneficiary %>% select(-DOD)
```

**Step 2:**  
<div class = "black">
Inpatient and Outpatient data sets- Missing values in Physician columns, Diagnosis codes, and procedure codes.

1) For Physician columns - Replace NAs with "None"
2) For Diagnosis codes  and procedure codes - Replace NAs with 0 
</div>

```{r replotting missing values after deleting some columns}
#replace_NAs_None <- function(df){
#df$AttendingPhysician <- factor(df$AttendingPhysician,levels=c(levels(df$AttendingPhysician),"None"))
#df$OperatingPhysician <- factor(df$OperatingPhysician,levels=c(levels(df$OperatingPhysician),"None"))
#df$OtherPhysician <- factor(df$OtherPhysician,levels=c(levels(df$df$OtherPhysician),"None"))
#df$AttendingPhysician[is.na(df$AttendingPhysician)] <- "None"
#df$OperatingPhysician[is.na(df$OperatingPhysician)] <- "None"
#df$OtherPhysician[is.na(df$OtherPhysician)] <- "None"
#return(df)
#}

#train_inpatient <- replace_NAs_None(train_inpatient)
train_inpatient <- train_inpatient %>% mutate_if(is.factor,fct_explicit_na,na_level="0")
train_inpatient[is.na(train_inpatient)] <-0 
#train_outpatient <- replace_NAs_None(train_outpatient)
train_outpatient <- train_outpatient %>% mutate_if(is.factor,fct_explicit_na,na_level="0")
train_outpatient[is.na(train_outpatient)] <- 0
```

#Feature Engineering
<div class = "black">
1) Chronic conditions are listed as 1=Yes, 2=No. We will convert 2 to 0 just for ease of computation 
2) Add a new column age will be more useful than date of birth
3) Adding a new column of state names 
4) Totalstay_days (Total days spent in the hospital) =  DischargeDt-AdmissionDt
5) Claimlength = ClaimEndDt-ClaimStartDt
6) Column Type with "Inpatient" and "Outpatient"
</div>

```{r converting 2s to 0s}
train_beneficiary[,10:20][train_beneficiary[,10:20]==2] <- 0
train_beneficiary <- train_beneficiary %>% mutate(Age=round(as.numeric(as.Date("2009-12-31")-DOB)/365))
train_beneficiary <- left_join(train_beneficiary,States)
```

```{r adding duration}
train_inpatient <- train_inpatient %>% mutate(Totalstay_days=round(as.numeric(DischargeDt-AdmissionDt))+1)
train_inpatient <- train_inpatient %>% mutate(Claimlength=round(as.numeric(ClaimEndDt-ClaimStartDt)))
train_inpatient <- train_inpatient %>% mutate(Type="Inpatient")

train_outpatient <- train_outpatient %>% mutate(Claimlength=round(as.numeric(ClaimEndDt-ClaimStartDt)))
train_outpatient <- train_outpatient %>% mutate(Type="Outpatient")
```

**Join the beneficiary and Inpatient, Outpatient datsets for analysis**

```{r joining datasets}
Merged_in_ben_fruad<- inner_join(train_inpatient,train_beneficiary)
Merged_in_ben_fruad<- inner_join(Merged_in_ben_fruad,train_labels)

Merged_out_ben_fraud <- inner_join(train_outpatient,train_beneficiary)
Merged_out_ben_fraud <- inner_join(Merged_out_ben_fraud,train_labels)

all_data<-bind_rows(Merged_in_ben_fruad,Merged_out_ben_fraud)
all_data<-all_data %>% mutate_if(is.factor,fct_explicit_na,na_level="0")
all_data$AdmissionDt[is.na(all_data$AdmissionDt)] <- as.Date("1970-01-01")
all_data$DischargeDt[is.na(all_data$DischargeDt)] <- as.Date("1970-01-01")
all_data[is.na(all_data)] <-0
all_data$Gender[all_data$Gender==2]<-0
all_data <- all_data %>% select(-DOB,-State)
```

**Ok, lets explore the data now.Now each row has a unique claim and various variables along with the labels column(Potential Fraud)**

#Exploratory data analysis

```{r plotting the target variable}
#ggplot(all_data,aes(x=factor(PotentialFraud)))+geom_bar()+geom_text(stat="count",aes(label=paste(round(stat(prop)*100,0),"%"),fontface="bold",group=1,vjust=2.0))+facet_wrap(~Type,scales="free_y")+ labs(y=" ",x="",title="Fraud claims in Inpatient and Outpatient data")+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text = element_text(face="bold",size=12))

#ggsave("total_ditb.png",plot20,dpi=300)

#ggplot(all_data,aes(x=factor(PotentialFraud)))+geom_bar()+geom_text(stat="count",aes(label=paste(round(stat(prop)*100,0),"%"),fontface="bold",group=1,vjust=2.0))+labs(y=" ",x=" ",title="Claims by provider class")+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text = element_text(face="bold",size=12))

#ggsave("total_ditb.png",plot20,dpi=300)


```
##Age and Fraud

```{r}
#Age distribution
#Adding Age bin
all_data <- all_data %>% mutate(Agebin=ifelse(Age>=20 & Age<=40,"20-40",
                            ifelse(Age>40 & Age<=60,"40-60",
                            ifelse(Age>60 & Age<=80,"60-80",
                            ifelse(Age>80 & Age<=100,"80-100","None")))))

ggplot (all_data,aes(x=Age,color=PotentialFraud,fill=PotentialFraud))+geom_histogram(aes(y=..density..),alpha=0.5,position="identity")+geom_density(alpha=0.2)+theme(axis.text = element_text(face="bold",size=12))+theme(axis.title = element_text(face="bold",size=12))

#Age vs Fraud
#ggplot(all_data,aes(x=PotentialFraud,y=Age,fill=PotentialFraud))+geom_boxplot()+theme(axis.text = element_text(face="bold",size=12))+theme(axis.title = element_text(face="bold",size=12))
#ggplot(all_data,aes(x=Age,y=PotentialFraud,fill=PotentialFraud))+geom_density_ridges(alpha=0.6,stat="binline",bins=20)+theme(axis.text = element_text(face="bold",size=12))
#ggsave("Age_ridge.png",plot4,dpi=300)
#ggsave("Age_box.png",plot5,dpi=300)

```
Insight:
<div class = "black">
Age seems to have no impact on Fraud
</div>

#Gender and Fraud
```{r}
ggplot(all_data,aes(x=as.factor(Gender),fill=PotentialFraud))+geom_bar(position = position_dodge())+theme(axis.text = element_text(face="bold",size=12))+labs(x="")+scale_x_discrete(labels=c("Female","Male"))+ theme(axis.title = element_text(face="bold",size=12))+geom_text(stat="count",aes(label=paste(round(stat(prop)*100,0),"%"),fontface="bold",group=1,vjust=2.0))
#ggsave("Gender.png",plot6,dpi=300)

#ggplot(all_data,aes(x=factor(PotentialFraud),fill=factor(Gender)))+geom_bar(position = position_dodge())+
 # geom_text(stat="count",aes(label=scales::percent(..prop..),group=1))
```
Insights:
<div class = "black">
There are more females in the dataset than males
No influence on fraud
</div>

#Race and Fraud
```{r }
 ggplot(all_data,aes(x=Race,fill=PotentialFraud))+geom_bar(position = position_dodge())+theme(axis.text = element_text(face="bold",size=12))+theme(axis.title = element_text(face="bold",size=12))
#ggsave("Race.png",plot7,dpi=300)
```

Insights:
<div class = "black">
1) Race is mostly populated with a single value (race 1), which can cause model bias. Therefore, remove this variable before modeling. 
</div>

#State and Fraud 

1) First lets take a look at fraudulent claims per state. Looks like California, Florida, New York, Pennsylvania, and Texas have higher fraudulent claims than other states

| State    | Total claims     | 
|:-------------:|:-------------:|
| California    | 30335 | 
| Florida     | 17512     | 
| New York | 17492      |
| Pennsylvania | 11448      |
| Texas | 10135      |


```{r }
ditch_the_axes <- theme(
axis.text = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.title = element_blank())
state_data <- all_data %>% group_by(State_name,PotentialFraud) %>% summarize(total=n())
state_data <- spread(state_data,PotentialFraud,total)
state_data <- state_data[-c(1),]
colnames(state_data) <- c("region","No","Yes")
state_data$region <- tolower(state_data$region)
states_map <- map_data("state")
map_state_date <- left_join(states_map,state_data,by="region")
state_abbs <- as.data.frame(cbind(state.abb,state.name))
colnames(state_abbs) <- c("state_abb","region")
state_abbs$region <- tolower(state_abbs$region)
map_state_date <- left_join(map_state_date,state_abbs,by="region")
state_names <- map_state_date %>% group_by(state_abb) %>% summarize(lat=0.5*(max(lat)+min(lat)),long=0.5*(max(long)+min(long)))
map_state_date <- map_state_date %>% mutate(total=No+Yes)

ggplot(map_state_date,aes(x=long,y=lat))+geom_polygon(aes(group=group,fill=Yes),color="black")+scale_fill_continuous(low="lightblue",high="darkblue")+geom_text(data=state_names,mapping=aes(x=long,y=lat,label=state_abb),color="white",size=3)+coord_fixed(1.3)+ditch_the_axes
```

2) Lets take a look at total claims per state to investigate if these states also have high total claims

```{r}

ggplot(map_state_date,aes(x=long,y=lat))+geom_polygon(aes(group=group,fill=total),color="black")+scale_fill_continuous(low="lightblue",high="darkblue")+geom_text(data=state_names,mapping=aes(x=long,y=lat,label=state_abb),color="white",size=3)+coord_fixed(1.3)+ditch_the_axes

```


**Number of claims from flagged providers per state correlates with total claims per state**
**NO CLEAR STATE BIAS**

3) Lets investigate if fraudulent provuders file claims across multiple states

```{r}
#ggsave("state1.png",plot8,dpi=300,width=9,height=9)
#ggsave("state2.png",plot9,dpi=300,width=9,height=9)

state_test <- all_data %>% select(Provider,State_name,PotentialFraud) %>% count(Provider,State_name,PotentialFraud) %>% spread(State_name,n) 
state_test[is.na(state_test)] <-0
state_test$total <- apply(state_test[,4:54],1,function(x)sum(x>0))
ggplot(state_test,aes(total))+geom_histogram()+facet_wrap(~PotentialFraud,scales="free_y")+theme(axis.text = element_text(face="bold",size=12))+theme(axis.title = element_text(face="bold",size=12))

#ggsave("state3.png",plot10,dpi=300)
#state_data %>% select(region,Yes) %>% arrange(desc(Yes))

```

**Looks like flagged providers file claims in more states than non-flagged providers** 

##Chronic conditions and Fraud 
```{r }
all_data$Total_chronicconds <- as.numeric(apply(all_data[,37:47],1,sum))
all_data <- all_data %>% mutate(chroniccond=ifelse(Total_chronicconds>0,"yes","no"))
#ggplot(all_data,aes(x=Total_chronicconds))+geom_histogram()+facet_wrap(~PotentialFraud,scales="free_y")
#ggplot(all_data,aes(Age,Total_chronicconds))+geom_bar(stat="identity")+facet_wrap(~PotentialFraud,scales="free_y")
#ggplot(all_data,aes(x=as.factor(PotentialFraud),y=Total_chronicconds))+geom_bar(stat="identity",position=position_dodge())
cc <- all_data %>% select(starts_with("Chronic"),PotentialFraud) %>% gather(chroniccond,value,starts_with("Chronic"))
cc %>% group_by(chroniccond,value,PotentialFraud) %>% summarize(total=n()) %>% ggplot(aes(x=reorder(chroniccond,total),y=total,fill=PotentialFraud))+geom_bar(stat="identity",position=position_dodge())+theme(axis.text.x = element_text(angle=90))
#cc

```

##Diagnosis codes and Fraud 

Do fraudulent providers use some diagnostic codes more frequently ?

```{r topdiagnosiscodesassociatedwithfraud}
Top_diagnosiscodes <- all_data %>% select(starts_with("ClmDiagnosisCode"),PotentialFraud,Type) %>% gather(Code,Value,starts_with("ClmDiagnosisCode")) %>% filter(PotentialFraud=="Yes")

Top_diagnosiscodes_nf <- all_data %>% select(starts_with("ClmDiagnosisCode"),PotentialFraud,Type) %>% gather(Code,Value,starts_with("ClmDiagnosisCode")) %>% filter(PotentialFraud=="No")

Overall_top_diagnosiscodes <- Top_diagnosiscodes %>% filter(Value!=0) %>% group_by(Value) %>% summarize(total=n()) %>% arrange(desc(total)) 

Overall_top_diagnosiscodes_nf <- Top_diagnosiscodes_nf %>% filter(Value!=0) %>% group_by(Value) %>% summarize(total=n()) %>% arrange(desc(total)) 

#plotting the top ten codes
Overall_top_diagnosiscodes[1:10,] %>% ggplot(aes(x=reorder(Value,total),y=total))+geom_bar(stat="identity")+theme(axis.text.x = element_text(angle=45))+theme(axis.text = element_text(face="bold",size=12))+theme(axis.title = element_text(face="bold",size=12))+labs(x="")

#Adding percent column
#Overall_top_diagnosiscodes <- Overall_top_diagnosiscodes %>% mutate(percent_fraud=total/212796)
#Overall_top_diagnosiscodes_nf<- Overall_top_diagnosiscodes_nf %>% mutate(percent_notfraud=total/345415)
all_diagnosis_codes <- inner_join(Overall_top_diagnosiscodes,Overall_top_diagnosiscodes_nf,by="Value")
all_diagnosis_codes <- all_diagnosis_codes %>% mutate(percent_fraud=total.x/212796)
all_diagnosis_codes <- all_diagnosis_codes %>% mutate(percent_notfraud=total.y/345415)

 ggplot(all_diagnosis_codes,aes(percent_fraud,percent_notfraud))+geom_point()+scale_x_log10()+scale_y_log10()+geom_abline(color="black")+theme(axis.text = element_text(face="bold",size=12))+theme(axis.title = element_text(face="bold",size=12))

#ggsave("diagcode1.png",plot11,dpi=300)
#ggsave("diagcode2.png",plot12,dpi=300)

```
Insights:
<div class = "black">
**Looks like some codes are strongly associated with fraudulent claims** 
</div>


##Procedure codes vs Fraud 

```{r }
Top_procedurecodes <- all_data %>% select(starts_with("ClmProcedureCode"),PotentialFraud,Type) %>% gather(Code,Value,starts_with("ClmProcedureCode")) %>% filter(PotentialFraud=="Yes")

Top_procedurecodes_nf <- all_data %>% select(starts_with("ClmProcedureCode"),PotentialFraud,Type) %>% gather(Code,Value,starts_with("ClmProcedureCode")) %>% filter(PotentialFraud=="No")

#Top_procedurecodes_group <- Top_procedurecodes %>% group_by(Code,Value) %>% summarize(total=n()) %>% arrange(desc(total)) %>% slice(1:10)

Overall_top_procedurecodes <- Top_procedurecodes %>% filter(Value!=0) %>% group_by(Value) %>% summarize(total=n()) %>% arrange(desc(total)) 
Overall_top_procedurecodes_nf <- Top_procedurecodes_nf %>% filter(Value!=0) %>% group_by(Value) %>% summarize(total=n()) %>% arrange(desc(total))
all_procedure_codes <- inner_join(Overall_top_procedurecodes,Overall_top_procedurecodes_nf,by="Value")
all_procedure_codes <- all_procedure_codes %>% mutate(percent_fraud = total.x/212796)
all_procedure_codes <- all_procedure_codes %>% mutate(percent_notfraud = total.y/345415)

ggplot(all_procedure_codes,aes(percent_fraud,percent_notfraud))+geom_point()+scale_x_log10()+scale_y_log10()+geom_abline(color="black")+theme(axis.text = element_text(face="bold",size=12))+theme(axis.title = element_text(face="bold",size=12))

Overall_top_procedurecodes[1:10,] %>% ggplot(aes(x=reorder(Value,total),y=total))+geom_bar(stat="identity")+theme(axis.text.x = element_text(angle=80))
#ggsave("proccode.png",plot13,dpi=300)
```

**Flagged providers file more inpatient claims which explains the frequency bias of procedure codes**

##Hospital stay and fraud 

Is there a difference in distributions of hospital stay between fraudulent and non-fraudulent providers?
```{r }
all_data %>% count(Totalstay_days,PotentialFraud) %>%  arrange(desc(n)) %>% filter(Totalstay_days!=0) %>% ggplot(aes(as.numeric(reorder(Totalstay_days,Totalstay_days)),n))+geom_bar(stat="identity")+facet_wrap(~PotentialFraud)+scale_x_continuous(limits=c(0,40),breaks=seq(0,40,5))+theme(axis.text = element_text(face="bold",size=12))+theme(axis.title = element_text(face="bold",size=12))+theme(axis.text.x = element_text(angle=90))+labs(y="",x="Totalstay(days)")

#ggsave("hospstay.png",plot14,dpi=300)
```


```{r Claim length and fraud}
#all_data %>% count(Claimlength,PotentialFraud) %>% filter(Claimlength!=0) %>% arrange(desc(n)) %>%  #ggplot(aes(Claimlength,n))+geom_bar(stat="identity")+facet_wrap(~PotentialFraud,scales="free_y")+theme(axis.text = element_text(face="bold",size=12))+theme(axis.title = element_text(face="bold",size=12))+labs(y="")

```

##Number of claims and Fraud 

Do fraudulent providers file more claims per patient?
```{r}
Totalclaims_byuser <- all_data %>% group_by(BeneID) %>% summarize(total=n())
Fraud_byuser <- all_data %>%count(BeneID,PotentialFraud) 
Fraud_byuser <- Fraud_byuser %>% spread(PotentialFraud,n)
Fraud_byuser[is.na(Fraud_byuser)]<-0
Totalclaims_byuser <- inner_join(Totalclaims_byuser,Fraud_byuser)
Totalclaims_byuser <- Totalclaims_byuser %>% mutate(Fraud = ifelse(Yes>0,"yes","no"))
ggplot(Totalclaims_byuser,aes(x=total,fill=Fraud))+geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
    scale_fill_manual(values=c("#69b3a2", "#404080"))+labs(fill="")+facet_wrap(~Fraud,scales="free_y")+theme(axis.text = element_text(face="bold",size=12))+theme(axis.title = element_text(face="bold",size=12))+labs(x="Total claims per user",y="")

#ggsave("claim.png",plot15,dpi=300)
```


```{r Total number of codes and Fraud  }
all_data$total_diagnosiscodes <- apply(all_data[,15:24],1,function(x)sum(x>0))
all_data$total_procedurecodes <- apply(all_data[,25:27],1,function(x)sum(x>0))
#ggplot(all_data,aes(x=total_diagnosiscodes))+geom_histogram(color="#e9ecef",binwidth=1,alpha=0.6,position="identity")+scale_fill_manual(values=c("#69b3a2", "#404080"))+facet_wrap(~PotentialFraud,scales="free_y")
#ggplot(all_data,aes(x=total_procedurecodes,fill=PotentialFraud))+geom_histogram(color="#e9ecef",binwidth=1,alpha=0.6,position="identity")+scale_fill_manual(values=c("#69b3a2", "#404080"))

```

```{r total physicians}
all_data$total_physicians <- apply(all_data[,7:9],1,function(x)sum(x>0))
#ggplot(all_data,aes(x=as.numeric(total_physicians)))+geom_histogram(color="#e9ecef",binwidth=1,alpha=0.6,position="identity")+scale_fill_manual(values=c("#69b3a2", "#404080"))+facet_wrap(~PotentialFraud,scales="free_y")

```

#Getting the dataset ready

* In our explortatory data analysis, we had 550k rows and 60 features.    
* In order to predict fradulent providers, we need to map the features onto the provider data which consists of 5410 rows.    
* For each provider, the features shown below in the feature engineering box were calculated 
* The final data set consists of 5410 rows and 21 features enumerated on per provider basis

![Flow chart depicting how data was enumerated on a per provider basis ](/Users/spandana/Desktop/testdataimage2.png)


```{r Getting the dataset ready }
top_codes_list <- c("4280","2720","2449","V5861","4011","42731","V5869","2724","25000","4019")
codes_data <- all_data %>% select(starts_with("ClmDiagnosisCode"),Provider) %>% gather(Code,codevalue,starts_with("ClmDiagnosisCode")) %>% group_by(Provider,codevalue) %>% summarize(total=n()) %>% filter(codevalue %in% top_codes_list)
codes_data <- spread(codes_data,codevalue,total)
Age_data <- all_data %>% select(Agebin,Provider) %>% gather(Age_bin,bin_value,Agebin) %>% group_by(Provider,bin_value) %>% summarize(total=n()) %>% spread(bin_value,total)
Staydays_data <- all_data %>% group_by(Provider,Type) %>% summarize(total=n())
Staydays_data <- Staydays_data %>% spread(Type,total)
Staydays_data_2 <- all_data %>% group_by(Provider) %>% summarize(Totalstay_days=sum(Totalstay_days))
Staydays_data <- inner_join(Staydays_data,Staydays_data_2)
Staydays_data <- Staydays_data %>% mutate(Totalstay_days=Totalstay_days/Inpatient)
Staydays_data <- Staydays_data %>% select(Provider,Totalstay_days)
Remaining_features <- all_data %>% group_by(Provider) %>% summarise(Total_diagnosiscodes=mean(total_diagnosiscodes),Total_chronicconds=mean(Total_chronicconds),Total_physicians = mean(total_physicians))


modeling_dataframe <- all_data %>% select(Provider,BeneID) %>% group_by(Provider) %>% mutate(Total_patients=n_distinct(BeneID))
modeling_dataframe <- modeling_dataframe %>% group_by(Provider,Total_patients) %>% summarize(Total_claims=n())
modeling_dataframe <- full_join(modeling_dataframe,codes_data)
modeling_dataframe <- full_join(modeling_dataframe,Age_data)
modeling_dataframe <- full_join(modeling_dataframe,state_test[,c(1,55)])
modeling_dataframe <- full_join(modeling_dataframe,Staydays_data)
modeling_dataframe <- full_join(modeling_dataframe,Remaining_features)
colnames(modeling_dataframe)[colnames(modeling_dataframe)=="total"] <-"Total_states"
modeling_dataframe <- modeling_dataframe %>% select(-None)
modeling_dataframe[is.na(modeling_dataframe)]<-0
modeling_dataframe <- full_join(modeling_dataframe,train_labels)
modeling_dataframe <- modeling_dataframe %>% mutate(PotentialFraud=ifelse(PotentialFraud=="Yes",1,0))
modeling_dataframe$PotentialFraud <- as.factor(modeling_dataframe$PotentialFraud)
colnames(modeling_dataframe)[4:17] <- c("Code_2449","Code_25000","Code_2720","Code_2724","Code_4011","Code_4019","Code_42731","Code_4280","Code_V5861","Code_5869","Age_20_40","Age_40_60","Age_60_80","Age_80_100")

```

```{r }
#Model
modeling_dataframe <- as.data.frame(modeling_dataframe)
modeling_dataframe <- modeling_dataframe %>% select(-Provider)
set.seed(143)
train_partition <- createDataPartition(modeling_dataframe$PotentialFraud,p=0.8,list=F)
train_model <- modeling_dataframe[train_partition,]
validate_model <- modeling_dataframe[-train_partition,]
```


#Modeling

* We will employ the following algorithms to generate models:   
  -Logistic Regression
  -Random Forest
  -Xtreme Gradient Boosting 
  
* For each model  
  -Train-Test split ratio - 80:20
  
* For Random Forest and XGBM   
  - Repested k-fold crodd validation (5 repeats of 10 fold cross validation)
  
* Since this is an imblanced data set, we will use Recall and Specificity instead of overall accuracy to validate our predictions


##Logistic Regression
```{r}
#Logistic regression model 
set.seed(123)
logisticmodel <- glm(PotentialFraud ~ .,data=train_model,family="binomial"(link="logit"))
summary(logisticmodel)
logpred <- predict(logisticmodel,validate_model,type="response")
logpred <- ifelse(logpred>0.5,1,0)
logpred_correct <- data.frame(target=validate_model$PotentialFraud,predicted=logpred,match=(validate_model$PotentialFraud==logpred))
#table(logpred>0.5,validate_model$PotentialFraud)
#print(length(logpred_correct$match[logpred_correct$match==TRUE])/count(validate_model))
ROCpred <- prediction(logpred,validate_model$PotentialFraud)
ROCperf <- performance(ROCpred,'tpr','fpr')
plot(ROCperf,colorize=TRUE,text.adj = c(-0.2,1.7))
```

|     | Actual Positives     |  Actual Negatives | 
|:-------------:|:-------------:|:-------------:|
| Predicted Positives    | 38(TP) | 6(FP) |
| Predicted Negatives     | 63(FN)     | 974(FN) |

TP = True positives (providers correctly identified as Fraud)      
TN = True negatives (providers correctly identitied as Not Fraud)     
FP = False positives (providers incorrectly identified as Fraud)    
FN = False negatives (providers incorreclt identified as not fraud)     

Accuracy = TP+TN/Total = 974+38/1081 = 93%

Recall= TP/Total Actual positives = 38/101 = 37%

**The overall accuracy is 93%. However, the goal of this project is to correctly identify the fraud providers accurately and the poor recall rate indicates that this model will perform poorly when it comes to predicting fraud providers**

Lets see how Random Forest and XGBM perform

##Random Forest and XGBM

|     | Logistic Regression |  Random Forest | XGBoost |
|:-------------:|:-------------:|:-------------:| :-------------:|
| True Positive    | 38 | 78 | 62 |
| False Negative     | 63   | 23 | 39 |
| Recall(%)     | 37   | 77 | 61 |
| Accuracy(%)    | 93  | 97 | 95 |


```{r}
#Random Forest 
#simple random forest with random forest package
#rf_model <- randomForest(PotentialFraud~.,data=train_model,ntree=1000,mtry=1,importance=TRUE)
#rf_pred <- predict(rf_model,validate_model,type="class")
#table(rf_pred,validate_model$PotentialFraud)

#searching for best mtry 
#rf_control <- trainControl(method="repeatedcv",number=5,repeats=3,search="grid")
#set.seed(123)
#tunegrid <- expand.grid(.mtry=c(1:15))
#rf_cv <- train(PotentialFraud~.,method="rf",metric="Accuracy",trControl= rf_control,
#       tuneGrid=tunegrid,
#       data=train_model,verbose=FALSE)
#print(rf_cv)
#plot(rf_cv)


#searching for best ntree 
#ntreegrid <- expand.grid(.mtry=c(sqrt(ncol(train_model))))
#modellist <- list()
#for( ntree in c(500, 1000, 1500)){
#  set.seed(123)
#  fit <- train(PotentialFraud~.,method="rf",metric="Accuracy",trControl= rf_control,
#       tuneGrid=ntreegrid,
#       data=train_model,verbose=FALSE)
#  key <- toString(ntree)
#  modellist[[key]] <- fit
#}
#results <- resamples(modellist)
#summary(results)
#dotplot(results)

rf_control <- trainControl(method="repeatedcv",number=5,repeats=3,search="grid")
#Final RF model
set.seed(123)
ntreegrid <- expand.grid(.mtry=c(1))
rf_final_model <- train(PotentialFraud~.,method="rf",metric="Accuracy",trControl=rf_control,tunegrid=ntreegrid,data=train_model,verbose=FALSE)
rf_final_pred <- predict(rf_final_model,validate_model,type="raw")
#table(rf_final_pred,validate_model$PotentialFraud)
test <- varImp(rf_final_model)
plot(test)
#ggsave("rf_plot.png",plot21,dpi=300)

```


```{r}
#XGBoost
set.seed(123)
xgbm_trainmatrix <- xgb.DMatrix(data = as.matrix(train_model[,-22]),label = as.matrix(train_model$PotentialFraud)) 
xgbm_testmatrix <- xgb.DMatrix(data = as.matrix(validate_model[,-22]),label=as.matrix(validate_model$PotentialFraud))

xgbm <-  xgboost(booster="gbtree",data = xgbm_trainmatrix, nfold = 5,nrounds = 2500, 
                 verbose = FALSE, objective = "binary:logistic",
                 nthread = 8,  gamma = 0.0468, max_depth = 6,
                 min_child_weight = 1.5, subsample = 0.5, colsample_bytree =0.283)
mat <- xgb.importance (feature_names = colnames(xgbm_trainmatrix),model = xgbm)
xgb.plot.importance (importance_matrix = mat[1:20]) 
xgbm_pred <- predict(xgbm,newdata = xgbm_testmatrix)
lvl<-c("N","Y")
xgbm_pred_label <- as.numeric(xgbm_pred>0.5)
#confusionMatrix(factor(xgbm_pred_label),validate_model$PotentialFraud)
xgb.pred <- prediction(xgbm_pred,validate_model$PotentialFraud)
xgb.perf <- performance(xgb.pred,"tpr","fpr")
#plot(xgb.perf,avg="threshold",colorize=TRUE,lwd=1,print.cutoffs.at=seq(0,1,by=0.05),text.adj=c(-0.5,0.5),text.cex=0.5)
#grid(col="lightgrey")
#axis(1,at=seq(0,1,by=0.1))
#axis(2,at=seq(0,1,by=0.1))
#max(xgbm$evaluation_log$train_error)
```

#Conclusions
<div class = "black">
* Random Forest predicts with highest accuracy - 77% Recall and 97% Accuracy
* Our model with 77% recall can accurately identify 161,000 fradulent claims. Each claim costs an average of $1500. So, the insurance company can potentially save ~$200 million
* Significant saving in avoiding investigations on all claims and can help process valid claims faster 
</div>


